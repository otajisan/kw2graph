import structlog
import asyncio
from typing import List, Dict, Any, Set

from gremlin_python.driver import client, serializer
from gremlin_python.driver.client import Client
from gremlin_python.driver.resultset import ResultSet
from gremlin_python.process.graph_traversal import __, constant

from kw2graph import config
from kw2graph.infrastructure.base import RepositoryBase

logger = structlog.get_logger(__name__)

# é–¢é€£èªå¥ã®æŠ½å‡ºçµæœã®å‹å®šç¾©
ExtractionResult = List[Dict[str, Any]]
# è¡¨ç¤ºç”¨ã®ã‚°ãƒ©ãƒ•æ§‹é€ ã®å‹ã‚’å®šç¾©
GraphData = Dict[str, List[Dict[str, Any]]]


class GraphDatabaseRepository(RepositoryBase):
    """
    Gremlinäº’æ›ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã€‚
    I/Oã¯asyncio.to_thread()ã‚’ä½¿ã£ã¦éåŒæœŸãƒ«ãƒ¼ãƒ—ã‹ã‚‰åˆ†é›¢ã™ã‚‹ã€‚
    """

    NODE_LABEL_KEYWORD = 'Keyword'
    NODE_LABEL_CATEGORY = 'Category'
    NODE_LABEL_CHANNEL = 'Channel'
    EDGE_LABEL_RELATED = 'RELATED_TO'
    EDGE_LABEL_IS_A = 'IS_A'
    EDGE_LABEL_BELONGS_TO = 'BELONGS_TO'

    def __init__(self, settings: config.Settings, client_instance: Client):
        super().__init__(settings)
        self.endpoint = settings.graphdb_host
        self.port = settings.graphdb_port
        self.url = f'ws://{self.endpoint}:{self.port}/gremlin'

        logger.info("Initializing GraphDatabaseRepository (Thread-Safe Client)", url=self.url)
        self.client: Client = client_instance

    # --- åŒæœŸ Gremlin I/Oå®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰ ---
    def _sync_execute_gremlin(self, query: str) -> List[Any]:
        """Gremlinã‚¯ã‚¨ãƒªã‚’åŒæœŸçš„ã«å®Ÿè¡Œã—ã¾ã™ã€‚"""
        if not self.client:
            raise ConnectionError("Gremlin Client is not initialized.")

        try:
            results: ResultSet = self.client.submit(query)
            return results.all().result()
        except Exception as e:
            logger.error("Synchronous Gremlin query execution failed.", query=query, error=str(e))
            raise

    # --- éåŒæœŸãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ ---

    async def _execute_gremlin(self, query: str) -> List[Any]:
        """éåŒæœŸã§ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã«Gremlin I/Oã‚’æŠ•ã’ã‚‹"""
        try:
            return await asyncio.to_thread(self._sync_execute_gremlin, query)
        except Exception as e:
            raise e

    async def upsert_node(self, label: str, name: str, properties: Dict[str, Any] = None) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®ãƒãƒ¼ãƒ‰ã‚’Upsertã—ã€ãã®IDã‚’è¿”ã—ã¾ã™ã€‚
        ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆã‚‚ã€propertiesã‚’ä¸Šæ›¸ãæ›´æ–°ã—ã¾ã™ã€‚
        """
        properties = properties or {}

        # 1. ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£æ›´æ–°ç”¨ã® Gremlin ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ§‹ç¯‰ (prop_parts)
        prop_parts = ""
        for key, value in properties.items():

            if isinstance(value, list):
                # iab_categoriesãªã©ã®ãƒãƒ«ãƒãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å¯¾å¿œ: å„è¦ç´ ã«å¯¾ã—ã¦ property() ã‚’ç¹°ã‚Šè¿”ã™
                for item in value:
                    # Gremlinæ§‹æ–‡: .property('key', 'value')
                    quoted_item = f"'{item}'"
                    prop_parts += f".property('{key}', {quoted_item})"

            elif isinstance(value, str):
                # entity_typeãªã©ã®ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
                gremlin_value = f"'{value}'"
                prop_parts += f".property('{key}', {gremlin_value})"

            else:
                # æ•°å€¤ãªã©ã®ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å‹
                gremlin_value = str(value)
                prop_parts += f".property('{key}', {gremlin_value})"

        # 2. Gremlin Upsert ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰: æ¤œç´¢/ä½œæˆå¾Œã«å±æ€§ã‚’é©ç”¨ (FINAL FIX)
        upsert_query = (
            f"g.V().has('{label}', 'name', '{name}')"
            f".fold().coalesce("
            f"  unfold(),"  # æ—¢å­˜ãƒãƒ¼ãƒ‰ã‚’è¦‹ã¤ã‘ã‚‹
            f"  addV('{label}').property('name', '{name}')"  # ãƒãƒ¼ãƒ‰ãŒãªã‘ã‚Œã° 'name' ã®ã¿ã§æ–°è¦ä½œæˆ
            f")"
            f"{prop_parts}"  # â˜… ä¿®æ­£: coalesce ã®å¤–ã§ã€æ—¢å­˜ãƒãƒ¼ãƒ‰ã¾ãŸã¯æ–°è¦ãƒãƒ¼ãƒ‰ã®ä¸¡æ–¹ã«ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’é©ç”¨
            f".id()"  # æœ€çµ‚çš„ã«ãƒãƒ¼ãƒ‰ã®IDã‚’è¿”ã™
        )

        try:
            results = await self._execute_gremlin(upsert_query)
            return str(results[0]) if results else None
        except Exception as e:
            logger.error("Synchronous Gremlin query execution failed.", query=upsert_query, error=str(e))
            raise

    # -----------------------------------------------------------------
    # â˜… ä¿®æ­£: ã‚¨ãƒƒã‚¸ Upsert ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ†é›¢ãƒ»æ±ç”¨åŒ– (æ±ç”¨åŒ–)
    # -----------------------------------------------------------------

    async def upsert_edge(self, from_id: str, to_id: str, label: str, score: float = None) -> None:
        """
        2ã¤ã®ãƒãƒ¼ãƒ‰é–“ã«ã‚¨ãƒƒã‚¸ã‚’Upsertã—ã¾ã™ã€‚
        """
        # ã‚¨ãƒƒã‚¸ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ã—ã¦ã‚¹ã‚³ã‚¢ã‚’å«ã‚ã‚‹ã‹åˆ¤æ–­
        score_prop = f".property('score', {score})" if score is not None else ""

        # Gremlin Edge Upsert ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
        edge_upsert_query = (
            f"g.V('{from_id}').as('a').V('{to_id}').coalesce("
            # 1. æ—¢å­˜ã‚¨ãƒƒã‚¸ã‚’æ¢ã™
            f"  inE('{label}').where(outV().is('a')),"
            # 2. ãªã‘ã‚Œã°æ–°ã—ã„ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã—ã€ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¨­å®š
            f"  addE('{label}').from('a')"
            # 3. ã©ã¡ã‚‰ã®å ´åˆã‚‚ã‚¹ã‚³ã‚¢ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ›´æ–°ï¼ˆscoreãŒãªã„å ´åˆã¯æ›´æ–°ã—ãªã„ï¼‰
            f"){score_prop}"
        )

        await self._execute_gremlin(edge_upsert_query)

    # -----------------------------------------------------------------
    # â˜… ä¿®æ­£: ãƒ¡ã‚¤ãƒ³ç™»éŒ²ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯å¤‰æ›´ (DIã«ã‚ˆã‚‹ãƒãƒ¼ãƒ‰/ã‚¨ãƒƒã‚¸ç™»éŒ²)
    # -----------------------------------------------------------------

    async def register_related_keywords(self,
                                        seed_keyword: str,
                                        extracted_data: ExtractionResult,
                                        channel_name: str = None) -> bool:  # â˜… ãƒãƒ£ãƒ³ãƒãƒ«åãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
        """
        GPTã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ£ãƒãƒ«åã‚’ã‚°ãƒ©ãƒ•ã«ç™»éŒ²ã—ã¾ã™ã€‚
        """
        logger.info("Starting registration to GraphDB.", seed_keyword=seed_keyword)

        try:
            # 1. ã‚·ãƒ¼ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰ã®Upsert
            seed_node_id = await self.upsert_node(self.NODE_LABEL_KEYWORD, seed_keyword)
            if not seed_node_id:
                logger.error("Failed to upsert seed keyword node.", keyword=seed_keyword)
                return False

            # 2. ãƒãƒ£ãƒ³ãƒãƒ«ãƒãƒ¼ãƒ‰ã¨ BELONGS_TO ã‚¨ãƒƒã‚¸ã® Upsert (ã‚µãƒ¼ãƒ“ã‚¹å›ºæœ‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜)
            if channel_name:
                channel_node_id = await self.upsert_node(self.NODE_LABEL_CHANNEL, channel_name, {'platform': 'YouTube'})
                if channel_node_id:
                    # ã‚·ãƒ¼ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«ã¸ã®é–¢é€£ä»˜ã‘ (ã‚¹ã‚³ã‚¢ã¯ä¸è¦)
                    await self.upsert_edge(seed_node_id, channel_node_id, self.EDGE_LABEL_BELONGS_TO)

            # 3. å„é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã® Upsert ã¨ã‚¨ãƒƒã‚¸ä½œæˆ
            for item in extracted_data:
                related_keyword = item['keyword']
                score = item['score']
                entity_type = item.get('entity_type', 'General')  # å­˜åœ¨ã—ãªã„å ´åˆã¯ 'General'
                iab_categories = item.get('iab_categories', [])  # å­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ

                # Categoryãƒãƒ¼ãƒ‰ç”¨ã®åå‰ã‚’å–å¾—ï¼ˆIABã‚«ãƒ†ã‚´ãƒªã®æœ€åˆã®è¦ç´ ã‚’ã‚«ãƒ†ã‚´ãƒªåã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ï¼‰
                category_name = iab_categories[0] if iab_categories else None

                # ãƒãƒ¼ãƒ‰ã«æ¸¡ã™ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ§‹ç¯‰
                node_properties = {
                    'entity_type': entity_type,
                    # ãƒªã‚¹ãƒˆå‹ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¯ Gremlin ã§ multi-property ã¨ã—ã¦æ ¼ç´ã•ã‚Œã‚‹
                    'iab_categories': iab_categories
                }

                # A. é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰ã®Upsert
                # â˜… ä¿®æ­£: å±æ€§ã‚’æ¸¡ã—ã¦ãƒãƒ¼ãƒ‰ã‚’Upsert
                related_node_id = await self.upsert_node(
                    self.NODE_LABEL_KEYWORD,
                    related_keyword,
                    properties=node_properties
                )

                if related_node_id:
                    # B. RELATED_TO ã‚¨ãƒƒã‚¸ã®Upsert (GPTã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨)
                    await self.upsert_edge(seed_node_id, related_node_id, self.EDGE_LABEL_RELATED, score=score)

                    # C. IS_A ã‚¨ãƒƒã‚¸ã®Upsert (ã‚«ãƒ†ã‚´ãƒªéšå±¤: IABã®Tier 1ã‚’Categoryãƒãƒ¼ãƒ‰ã¨ã—ã¦åˆ©ç”¨)
                    if category_name:
                        # Categoryãƒãƒ¼ãƒ‰ã®Upsert (ã‚«ãƒ†ã‚´ãƒªåã¯ IAB Tier 1 ã‚’åˆ©ç”¨)
                        category_node_id = await self.upsert_node(self.NODE_LABEL_CATEGORY, category_name)
                        if category_node_id:
                            # é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã¸ã®éšå±¤ã‚¨ãƒƒã‚¸ã‚’ç™»éŒ² (ã‚¹ã‚³ã‚¢ã¯ä¸è¦)
                            await self.upsert_edge(related_node_id, category_node_id, self.EDGE_LABEL_IS_A)

            logger.info("GraphDB registration finished successfully.", seed_keyword=seed_keyword)
            return True

        except Exception as e:
            logger.error("GraphDB registration failed due to a critical error.", seed_keyword=seed_keyword,
                         error=str(e))
            return False

    # --- ã‚°ãƒ©ãƒ•å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ ---

    async def fetch_related_graph(
            self,
            seed_keyword: str,
            max_depth: int = 2,
            min_score: float = 0.0,
            entity_type: str | None = None,
            iab_category: str | None = None
    ) -> GraphData:
        logger.info("Fetching graph data with filters.",
                    seed_keyword=seed_keyword,
                    max_depth=max_depth,
                    min_score=min_score,
                    entity_type=entity_type,
                    iab_category=iab_category)

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®Gremlinã‚¯ã‚¨ãƒªéƒ¨å“ã‚’æ§‹ç¯‰

        # 1. ãƒãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿éƒ¨å“ (entity_type, iab_category)
        # ãƒãƒ¼ãƒ‰å–å¾—å¾Œã® project/by ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚‚ä½¿ç”¨ã™ã‚‹ãŸã‚ã€å¿…è¦ãªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚‚ project ã§å–å¾—ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
        node_filter_parts = ""

        # a) entity_type ãƒ•ã‚£ãƒ«ã‚¿
        if entity_type:
            node_filter_parts += f".has('entity_type', '{entity_type}')"

        # b) iab_category ãƒ•ã‚£ãƒ«ã‚¿ (iab_categoriesã¯ãƒªã‚¹ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ä»®å®š)
        if iab_category:
            # iab_categories ãƒªã‚¹ãƒˆã®ä¸­ã«æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªãŒå«ã¾ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã®ã¿ã‚’é¸æŠ
            node_filter_parts += f".where(values('iab_categories').unfold().is('{iab_category}'))"

        # 2. ã‚¨ãƒƒã‚¸ãƒ•ã‚£ãƒ«ã‚¿éƒ¨å“ (min_score)
        # score ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒ min_score ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨
        edge_filter_parts = f".has('{self.EDGE_LABEL_RELATED}', 'score', gt({min_score}))"

        # ----------------------------------------------------
        # 3. ãƒãƒ¼ãƒ‰å–å¾—ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
        # ----------------------------------------------------

        # ãƒãƒ¼ãƒ‰å–å¾—ã‚¯ã‚¨ãƒª: (æœ€çµ‚ä¿®æ­£ç‰ˆ - constant() ã‚’ä½¿ç”¨)
        nodes_query = (
            f"g.V().has('{self.NODE_LABEL_KEYWORD}', 'name', '{seed_keyword}')"
            f"{node_filter_parts}.as('start')."
            f"repeat(both('{self.EDGE_LABEL_RELATED}')).times({max_depth}).emit()."
            f"union(identity(), select('start'))."
            f"dedup()"
            f"{node_filter_parts}"
            f".project('id', 'name', 'entity_type', 'iab_categories')"
            f".by(id())"
            f".by(coalesce(values('name'), constant('')))"

            f".by(coalesce(values('entity_type'), __.constant('')))"  # __.constant('') ã‚’ä½¿ç”¨
            f".by(values('iab_categories').fold().coalesce(unfold(), __.constant([])))"  # __.constant([]) ã‚’ä½¿ç”¨
            f".toList()"
        )

        # ----------------------------------------------------
        # 4. ã‚¨ãƒƒã‚¸å–å¾—ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
        # ----------------------------------------------------

        # ã‚¨ãƒƒã‚¸å–å¾—ã‚¯ã‚¨ãƒª: (å®‰å®šç‰ˆã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¿½åŠ )
        edges_query = (
            f"g.V().has('{self.NODE_LABEL_KEYWORD}', 'name', '{seed_keyword}')."
            f"repeat(bothE('{self.EDGE_LABEL_RELATED}').otherV()).times({max_depth})."
            f"bothE('{self.EDGE_LABEL_RELATED}').dedup()"
            f"{edge_filter_parts}"  # ã‚¨ãƒƒã‚¸ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆmin_scoreï¼‰ã‚’é©ç”¨
            f".project('id', 'score', 'from_id', 'to_id')"
            f".by(id())"
            f".by(coalesce(values('score'), constant(0.0)))"
            f".by(__.outV().id())"
            f".by(__.inV().id())"
            f".toList()"
        )

        # ----------------------------------------------------
        # 5. å®Ÿè¡Œã¨çµæœã®æ•´å½¢
        # ----------------------------------------------------

        try:
            raw_nodes = await self._execute_gremlin(nodes_query)
            raw_edges = await self._execute_gremlin(edges_query)
        except Exception as e:
            logger.error("Failed to fetch graph data from Gremlin (Filtered Query).", error=str(e))
            return {"nodes": [], "edges": []}

        # 6. çµæœã®æ•´å½¢ï¼ˆPythonå´ã§çµåˆã¨å‹å¤‰æ›ï¼‰
        nodes = {}
        edges = []

        # ãƒãƒ¼ãƒ‰æ•´å½¢ (Long IDã‚’Stringã«ã€nameã‚’labelã«, ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’è¿½åŠ )
        for item in raw_nodes:
            iab_categories_raw = item.get('iab_categories')

            # ğŸ’¡ ä¿®æ­£: iab_categories ãŒãƒªã‚¹ãƒˆã§ãªã„ (å˜ä¸€ã®æ–‡å­—åˆ—ã§ã‚ã‚‹) å ´åˆã¯ãƒªã‚¹ãƒˆåŒ–
            if iab_categories_raw is None:
                # Gremlinã‹ã‚‰ä½•ã‚‚è¿”ã•ã‚Œãªã‹ã£ãŸå ´åˆï¼ˆå±æ€§ãªã—ãƒãƒ¼ãƒ‰ï¼‰
                final_iab_categories = []
            elif isinstance(iab_categories_raw, str):
                # å˜ä¸€ã®æ–‡å­—åˆ—ãŒè¿”ã•ã‚ŒãŸå ´åˆï¼ˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒä¸€ã¤ã ã‘ã®å ´åˆï¼‰
                final_iab_categories = [iab_categories_raw]
            elif not isinstance(iab_categories_raw, list):
                # ãƒªã‚¹ãƒˆã§ãªã„ãŒ None/str ã§ã‚‚ãªã„äºˆæœŸã›ã¬å‹ã®å ´åˆã€ãƒªã‚¹ãƒˆã«å¤‰æ› (å®‰å…¨ç­–)
                final_iab_categories = [str(iab_categories_raw)]
            else:
                # æ—¢ã«ãƒªã‚¹ãƒˆã§ã‚ã‚‹å ´åˆ
                final_iab_categories = iab_categories_raw

            node_id = str(item.get('id'))
            if node_id not in nodes:
                nodes[node_id] = {
                    "id": node_id,
                    "label": item.get('name'),
                    "group": self.NODE_LABEL_KEYWORD,  # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ã¯ 'Keyword' ã§å›ºå®š
                    "entity_type": item.get('entity_type'),  # â˜… æ–°ã—ã„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
                    "iab_categories": final_iab_categories  # â˜… æ–°ã—ã„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
                }

        # ã‚¨ãƒƒã‚¸æ•´å½¢ (Long IDã‚’Stringã«ã€BigDecimalã‚’Floatã«)
        for item in raw_edges:
            score_value = item.get('score')

            # BigDecimalã‚’floatã«å¤‰æ›
            if hasattr(score_value, 'unscaled_value') and hasattr(score_value, 'scale'):
                score_float = float(score_value.unscaled_value) / (10 ** score_value.scale)
            else:
                score_float = float(score_value)

            edges.append({
                "id": str(item.get('id')),
                "from_node": str(item.get('from_id')),
                "to_node": str(item.get('to_id')),
                "score": score_float
            })

        # 6. çµæœã®æ•´å½¢ï¼ˆPythonå´ã§çµåˆã¨å‹å¤‰æ›ï¼‰
        nodes = {}
        edges = []

        # ... (æ—¢å­˜ã®ãƒãƒ¼ãƒ‰æ•´å½¢ãƒ­ã‚¸ãƒƒã‚¯)
        for item in raw_nodes:
            # ... (iab_categories ã®ãƒªã‚¹ãƒˆåŒ–ãƒ­ã‚¸ãƒƒã‚¯)

            node_id = str(item.get('id'))
            if node_id not in nodes:
                nodes[node_id] = {
                    "id": node_id,
                    "label": item.get('name'),
                    "group": self.NODE_LABEL_KEYWORD,
                    "entity_type": item.get('entity_type'),
                    "iab_categories": final_iab_categories
                }

        # ... (æ—¢å­˜ã®ã‚¨ãƒƒã‚¸æ•´å½¢ãƒ­ã‚¸ãƒƒã‚¯)
        for item in raw_edges:
            # ... (ã‚¹ã‚³ã‚¢ã®floatå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯)

            edges.append({
                "id": str(item.get('id')),
                "from_node": str(item.get('from_id')),
                "to_node": str(item.get('to_id')),
                "score": score_float
            })

        # ----------------------------------------------------
        # 7. ã€è¿½åŠ ã€‘å­¤ç«‹ãƒãƒ¼ãƒ‰ã®é™¤å» (Orphan Node Removal)
        # ----------------------------------------------------

        # a. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚¨ãƒƒã‚¸ã«å«ã¾ã‚Œã‚‹ãƒãƒ¼ãƒ‰IDã‚’åé›†
        connected_node_ids: Set[str] = set()
        for edge in edges:
            # ã‚¨ãƒƒã‚¸ãŒæ®‹ã£ã¦ã„ã‚‹ãªã‚‰ã€ãã®ä¸¡ç«¯ã®ãƒãƒ¼ãƒ‰ã¯æ¥ç¶šã•ã‚Œã¦ã„ã‚‹
            connected_node_ids.add(edge['from_node'])
            connected_node_ids.add(edge['to_node'])

        # b. æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦æœ€çµ‚ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        final_nodes = []
        for node_id, node_data in nodes.items():
            # Edgeã®ã„ãšã‚Œã‹ã®ç«¯ç‚¹ã«å«ã¾ã‚Œã‚‹ãƒãƒ¼ãƒ‰ã®ã¿ã‚’æ¡ç”¨
            if node_id in connected_node_ids:
                final_nodes.append(node_data)

        # æœ€çµ‚çš„ãªæˆ»ã‚Šå€¤ã¨ã—ã¦ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’è¿”ã™
        return {"nodes": final_nodes, "edges": edges}  # nodes.values() ã§ã¯ãªã final_nodes ã‚’ä½¿ç”¨ã™ã‚‹

    async def get_new_and_eligible_keywords(self,
                                            seed_keyword: str,
                                            min_score: float,
                                            entity_type: str,
                                            max_depth: int = 1) -> List[str]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«åˆè‡´ã—ã€ã‹ã¤ã€ã¾ã èµ·ç‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦ç™»éŒ²ã•ã‚Œã¦ã„ãªã„
        æ–°ã—ã„ï¼ˆNewï¼‰ã®é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’GraphDBã‹ã‚‰ç™ºè¦‹ã—ã¾ã™ã€‚

        ã“ã®å‡¦ç†ã¯ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãªã®ã§ã€asyncio.to_thread ã§å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚

        :return: æ¡ä»¶ã‚’æº€ãŸã™æ–°è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
        """

        # 1. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®å®šç¾©
        # - entity_typeãŒæŒ‡å®šå€¤ã§ã‚ã‚‹ã“ã¨
        # - scoreãŒmin_scoreä»¥ä¸Šã§ã‚ã‚‹ã“ã¨

        # 2. Gremlin ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
        # (1) èµ·ç‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰V1ã‹ã‚‰é–¢é€£ã‚¨ãƒƒã‚¸ã‚’è¾¿ã‚Šã€ãƒãƒ¼ãƒ‰V2ã«åˆ°é”
        # (2) V2ãŒæŒ‡å®šã•ã‚ŒãŸ entity_type ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª
        # (3) V1->V2ã®ã‚¨ãƒƒã‚¸ãŒ min_score ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        # (4) V2ã‚’èµ·ç‚¹ã¨ã—ã¦ã€Œã¾ã RELATED_TOã‚¨ãƒƒã‚¸ãŒå‡ºã•ã‚Œã¦ã„ãªã„ã€ã“ã¨ã‚’ç¢ºèª (æ–°è¦æ€§ãƒã‚§ãƒƒã‚¯)

        query = (
            f"g.V().has('{self.NODE_LABEL_KEYWORD}', 'name', '{seed_keyword}')."
            f"outE('{self.EDGE_LABEL_RELATED}').has('score', gt({min_score})).inV().as('target')."
            f"has('entity_type', '{entity_type}')."
            f"where(outE('{self.EDGE_LABEL_RELATED}').count().is(0))."  # ğŸ’¡ æ–°è¦æ€§ãƒã‚§ãƒƒã‚¯: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ã‹ã‚‰å¤–å‘ãã®ã‚¨ãƒƒã‚¸ãŒãªã„ã“ã¨ï¼ˆã¤ã¾ã‚Šã€ã¾ã èµ·ç‚¹ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ãªã„ï¼‰
            f"values('name').toList()"
        )

        try:
            results = await asyncio.to_thread(self._sync_execute_gremlin, query)
            # results ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å (str) ã®ãƒªã‚¹ãƒˆ
            return [str(name) for name in results]

        except Exception as e:
            logger.error("Failed to fetch new eligible keywords from Gremlin.", error=str(e))
            return []
